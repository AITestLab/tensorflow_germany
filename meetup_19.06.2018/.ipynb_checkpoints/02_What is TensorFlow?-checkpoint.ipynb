{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome To Tensorflow - Germany Group "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What’s TensorFlow™?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "TensorFlow was originally created by researchers at Google as a single infrastructure for machine learning in both production and research. Later, an implementation of it was open sourced under the Apache 2.0 License in November 2015. On the Tensorflow website, we see:\n",
    "\n",
    "“TensorFlow™ is an open source software library for \n",
    "numerical computation using data flow graphs.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**[Tensorflow official Documentation ](https://www.tensorflow.org/api_docs/)**\n",
    "\n",
    "**Given the plethora of ML/DL libraries, why did we choose Tensorflow? **\n",
    "\n",
    "\n",
    "For a framework to be useful in production, it needs to be efficient, scalable, and maintainable. For research, the framework needs to have flexible operations that can be combined in novel ways. Alternative frameworks are either flexible enough for research but less scalable, such as Chainer and PyTorch, or scalable but less flexible, such as Caffe and MXNet. TensorFlow is both flexible and scalable, allowing users to streamline from research into production.\n",
    "\n",
    "\n",
    "This unique position allowed TensorFlow to grow quickly. It’s currently being used by big companies such as Google, OpenAI, NVIDIA, Intel, SAP, eBay, Airbus, Uber, Airbnb, Snap, Dropbox and startups alike. By the number of stars and related repositories on GitHub as of Jan 11, 2018, TensorFlow is by far the most popular machine learning library with more than 85.4k stars and 25.3k related repositories, twice as much as the total stars and related repositories of Caffe, PyTorch, Torch, and Theano combined. It’s said that the rise of TensorFlow is the reason why the support for Theano was discontinued in September 2017. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First things first ( import tensorflow library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print('Tensorflow Version :{}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your first TensorFlow program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a graph.\n",
    "hello = tf.constant('Hello TenorFlow', dtype=tf.string)\n",
    "a = tf.constant(3., dtype=tf.float32, name='first_constant')\n",
    "b = tf.constant(4., name='second_constant')\n",
    "c = tf.add(a,b)\n",
    "d = tf.constant(3., name='third_constant')\n",
    "e = tf.multiply(c,d)\n",
    "\n",
    "# Launch the graph in a session and evaluate the ops created when we build the graph\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(hello))\n",
    "    print(sess.run(e))\n",
    "    print(sess.run([a, b, c]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensors** are the basic elements of computation and a fundamental data structure in TensorFlow. Probably the only data structure that you need to learn to use TensorFlow. A tensor is an n-dimensional collection of data, identified by rank, shape, and type.\n",
    "\n",
    "\n",
    "**Rank** is the number of dimensions of a tensor, and shape is the list denoting the size in each dimension. A tensor can have any number of dimensions. You may be already familiar with quantities that are a zero-dimensional collection (scalar), a one-dimensional collection (vector), a two-dimensional collection (matrix), and a multidimensional collection.\n",
    "\n",
    "A ```scalar```  value is a tensor of rank 0 and thus has a shape of [1]. \n",
    "\n",
    "A ```vector``` or a one-dimensional array is a tensor of rank 1 and has a shape of [columns] or [rows].(column vector or row vector) \n",
    "\n",
    "A ```matrix``` or a two-dimensional array is a tensor of rank 2 and has a shape of [rows, columns].\n",
    "\n",
    "A ``three-dimensional array``` would be a tensor of rank 3.\n",
    "\n",
    "\n",
    "An ```n-dimensional array``` would be a tensor of rank n.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example what is Scalar, Vector , Matrix and Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The data model in TensorFlow is represented by tensors. Without using complex mathematical definitions, we can say that a tensor (in TensorFlow) identifies a multidimensional numerical array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = tf.constant(100)\n",
    "vector = tf.constant([1,2,3,4,5])\n",
    "matrix = tf.constant([[1,2,3],[4,5,6]])\n",
    "cube_matrix = tf.constant([[[1],[2],[3]],[[4],[5],[6]],[[7],[8],[9]]])\n",
    "\n",
    "print(scalar)\n",
    "print(vector)\n",
    "print(matrix)\n",
    "print(cube_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see that if we try to print we can not see the value , we get only Name, Shape, dtype of the tensor which is  created. With this in fact we are building the graph.\n",
    "\n",
    "Working with Tensors in Tensorflow require creating tf.Session(). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tensors can be created in the following ways:\n",
    "\n",
    "    1.By defining constants, operations, and variables, and passing the values to their constructor.\n",
    "    2.By defining placeholders and passing the values to session.run().\n",
    "    3.By converting Python objects such as scalar values, lists, and NumPy arrays with the tf.convert_to_tensor() function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Constant\n",
    "\n",
    "The constant valued tensors are created using the tf.constant() function that has the following signature:\n",
    "```python:\n",
    "tf.constant(\n",
    "    value,\n",
    "    dtype=None,\n",
    "    shape=None,\n",
    "    name='Const',\n",
    "    verify_shape=False\n",
    ")\n",
    "```\n",
    "Args:\n",
    "    - value: A constant value (or list) of output type dtype.\n",
    "    - dtype: The type of the elements of the resulting tensor.\n",
    "    - shape: Optional dimensions of resulting tensor.\n",
    "    - name: Optional name for the tensor.\n",
    "    - verify_shape: Boolean that enables verification of a shape of values.\n",
    "    \n",
    "Returns:\n",
    " Constant Tensor\n",
    " \n",
    "We can define tf.constant as scalar , vector , matrix or higher rank tensor 4D etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we will use Interactive Session\n",
    "sess = tf.InteractiveSession()#Here we will use tf.InteractiveSession instead tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines a constant tensor c1, gives it value 5, and name it x.\n",
    "c1=tf.constant(5,name='x')\n",
    "#Defines a constant tensor c2 gives it value 6.0 and name it y\n",
    "c2=tf.constant([6.0,2.0],name='y')\n",
    "#Defines a constant tensor c3 gives it avlue 7.0 and name it z \n",
    "c3=tf.constant([[2,3],[4,5]],tf.float64,name='z')\n",
    "#Defines a constant tensor c4 gives \n",
    "c4 = tf.constant(3.4, dtype=tf.float32, shape=(1,2,3,3))\n",
    "print('c1 (x): ',c1)\n",
    "print('c1 (x): ', '\\n',c1.eval())\n",
    "\n",
    "print('c2 (y): ',c2)\n",
    "print('c2 (y): ', '\\n', c2.eval())\n",
    "print('c3 (z): ',c3,)\n",
    "print('c3 (z): ','\\n',c3.eval())\n",
    "print('c4 ():  ',c4) # here you can see that we didnt assing name and Tensorflow gives default name Const_x:x\n",
    "print('c4 ():  ','\\n',c4.eval())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why we are using Tensorflow Constant:\n",
    "\n",
    "As the name suggest the value of the constant remains the same and we can not assign or change the values defined at first. It will become more clear when we explain the tf.placeholders and tf.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Tensorflow Variables](https://www.tensorflow.org/programmers_guide/variables)\n",
    "\n",
    ">A TensorFlow variable is the best way to represent shared, persistent state manipulated by your program.Variables are manipulated via the ```tf.Variable class```. A ```tf.Variable``` represents a tensor whose value can be changed by running ops on it.\n",
    "\n",
    "**Creating Variables**\n",
    "\n",
    "The best way to create a variable is to call the ```tf.get_variable``` function, but also they can be created using ```tf.Variable```.This function requires you to specify the Variable's name. This name will be used by other replicas to access the same variable, as well as to name this variable's value when checkpointing and exporting models. ```tf.get_variable``` also allows you to reuse a previously created variable of the same name, making it easy to define models which reuse layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables with tf.get_variable\n",
    "with tf.variable_scope('variable', reuse=tf.AUTO_REUSE):\n",
    "    s = tf.get_variable(\"scalar\", dtype=tf.float32,initializer=tf.constant(2.))\n",
    "    m = tf.get_variable(\"matrix\",dtype=tf.float32, initializer=tf.constant([[0., 1.], [2., 3.]]))\n",
    "    #Q: Why we are using tf.constant but this is tf.Variable?\n",
    "    #A: tf.constant is an op , tf.Variable is a class with many ops\n",
    "    W = tf.get_variable(\"big_matrix\",dtype=tf.float32, shape=(784, 10), initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets try to run the Session using Variables create before**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runinng this cell will give you error:FailedPreconditionError: Attempting to use uninitialized value Variable\n",
    "#with tf.Session() as sess:\n",
    "#    print(sess.run(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runing Session for using Variables always must be followed using Initializer.\n",
    "#Initializer is an op. You need to execute it within the context of a session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())# Very Important \n",
    "    print(sess.run(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Variable initializers must be run explicitly before other ops in model can be run. The easiest way to do that is to add an op that runs all the variable initializers, and run that op before using the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few options for initializing variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The easiest way is initializing all variables at once:\n",
    "#Same as the one above but here is presented just for clarity \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize only a subset of variables:\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.variables_initializer([s, m]))\n",
    "    print(sess.run([a,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a single variable\n",
    "with tf.Session() as sess:\n",
    "    sess.run(s.initializer)\n",
    "    print(s)\n",
    "    print(s.eval())#here you can see we can also use eval() for runing the variable instead of sess.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets just initialize a single variable but executing different\n",
    "#with tf.Session() as sess:\n",
    "#    sess.run(s.initializer)\n",
    "#    print(m.eval())#Different variable from the one that we initialize ###you will get ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets try some operations with Variables and change the values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('new_variables', reuse=tf.AUTO_REUSE):\n",
    "    matrix_new = tf.get_variable('matrix',dtype=tf.float32 ,shape=(2,2), initializer=tf.ones_initializer)\n",
    "matrix_new.assign_add(tf.fill([2,2], 4.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(matrix_new)\n",
    "    print(matrix_new.eval())#same as print(sess.run(matrix_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So we need to create op which will be executed inside of the Session\n",
    "assign_op = matrix_new.assign_add(tf.fill([2,2], 4.))\n",
    "with tf.Session() as sess:\n",
    "    #Init\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #Here the matrix is printed as we created the variable(no change)\n",
    "    print(sess.run(matrix_new))\n",
    "    # Run the op that we created - changing the value of the matrix new \n",
    "    print('-'*10)\n",
    "    sess.run(assign_op)\n",
    "    #Second run of the variable gives us new value\n",
    "    print(sess.run(matrix_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Placeholders and Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Tensorflow Placeholder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "While constants allow us to provide a value at the time of defining the tensor, the placeholders allow us to create tensors whose values can be provided at runtime. TensorFlow provides the tf.placeholder() function with the following signature to create placeholders:\n",
    "\n",
    "[tf.placeholder Documentation](https://www.tensorflow.org/api_docs/python/tf/placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "y = tf.placeholder(tf.float32, name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Tensoflow Operations\n",
    "\n",
    "TensorFlow provides us with many operations that can be applied on Tensors. An operation is defined by passing values and assigning the output to another tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Arithmetic operations**\n",
    "\n",
    "tf.add, tf.subtract, tf.multiply, tf.scalar_mul, tf.div, tf.divide, tf.truediv, tf.floordiv, tf.realdiv, tf.truncatediv, tf.floor_div, tf.truncatemod, tf.floormod, tf.mod, tf.cross\n",
    "\n",
    "**Basic math operations**\n",
    "\n",
    "tf.add_n, tf.abs, tf.negative, tf.sign, tf.reciprocal, tf.square, tf.round, tf.sqrt, tf.rsqrt, tf.pow, tf.exp, tf.expm1, tf.log, tf.log1p, tf.ceil, tf.floor, tf.maximum, tf.minimum, tf.cos, tf.sin, tf.lbeta, tf.tan, tf.acos, tf.asin, tf.atan, tf.lgamma, tf.digamma, tf.erf, tf.erfc, tf.igamma, tf.squared_difference, tf.igammac, tf.zeta, tf.polygamma, tf.betainc, tf.rint\n",
    "\n",
    "\n",
    "**Matrix math operations** \t\n",
    "tf.diag, tf.diag_part, tf.trace, tf.transpose, tf.eye, tf.matrix_diag, tf.matrix_diag_part, tf.matrix_band_part, tf.matrix_set_diag, tf.matrix_transpose, tf.matmul, tf.norm, tf.matrix_determinant, tf.matrix_inverse, tf.cholesky, tf.cholesky_solve, tf.matrix_solve, tf.matrix_triangular_solve, tf.matrix_solve_ls, tf.qr, tf.self_adjoint_eig, tf.self_adjoint_eigvals, tf.svd\n",
    "\n",
    "\n",
    "Note: List above is not some complete there is much more and also please note that as for each new release there is some updates in Tensorflow so there may be changes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use tensorflow opeartions and tensorflow placeholders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Artihmetic Operations \n",
    "add_op = tf.add(x,x)\n",
    "substract_op = tf.subtract(x,y)\n",
    "multiply_op = tf.multiply(x,y)\n",
    "division_op = tf.divide(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using placeholders means that data will come in runtime of the tensorflow graph. So we need to define python dictionary which will be used to feed the values in to the Session for computing the operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_one = {x:3. ,y:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    add,substract, multuply, division = sess.run([add_op,\n",
    "                                                  substract_op, \n",
    "                                                  multiply_op, \n",
    "                                                  division_op], \n",
    "                                                 feed_dict=feed_dict_one)\n",
    "    print(' 1.add_op Result:{},\\n 2.substract_op Result: {},\\n 3.multiply_op Result: {},\\n 4.division_op Result: {}'.format(add, \n",
    "                                                                                                             substract,\n",
    "                                                                                                             multuply,\n",
    "                                                                                                             division))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeds and Placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four methods of getting data into a TensorFlow program:\n",
    "\n",
    "    - tf.data API: Easily construct a complex input pipeline. (preferred method)\n",
    "    - Feeding: Python code provides the data when running each step.\n",
    "    - QueueRunner: a queue-based input pipeline reads the data from files at the beginning of a TensorFlow graph.\n",
    "    - Preloaded data: a constant or variable in the TensorFlow graph holds all the data (for small data sets).\n",
    "    \n",
    "    \n",
    ">Feeding using the feed_dict argument is the least efficient way to feed data into a TensorFlow execution graph and should only be used for small experiments needing small datasets. It can also be used for debugging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tensors from Python objects\n",
    "\n",
    "\n",
    "We can create tensors from Python objects such as lists and NumPy arrays, using the ```tf.convert_to_tensor()```\n",
    " operation with the following signature:\n",
    " \n",
    " \n",
    " Let we see few examples of creating tensor from python objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_x = 4\n",
    "\n",
    "array_1d = np.array([1,2,3,4,5.99])\n",
    "array_2d = np.array([(1,2,3,4,5.99),(2,3,4,5,6.99),(3,4,5,6,7.99)])\n",
    "array_3d = np.array([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "\n",
    "scalar_x_tf = tf.convert_to_tensor(scalar_x, name='scalar_converted')\n",
    "array_1d_tf = tf.convert_to_tensor(array_1d, dtype=tf.float32)\n",
    "array_2d_tf = tf.convert_to_tensor(array_2d)\n",
    "array_3d_tf = tf.convert_to_tensor(array_3d)\n",
    "\n",
    "print(scalar_x_tf)\n",
    "print(array_1d_tf)\n",
    "print(array_2d_tf)\n",
    "print(array_3d_tf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
